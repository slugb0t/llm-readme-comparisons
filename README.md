# Overview

This repository is a collection of prompts and outputs from various AI models, including DeepSeek , ChatGPT 4.1 mini (Free tier) and Copilot (GPT 4.1) documentation based on GitHub's best practices, open source documentation standards and examples provided in [matiassingers/awesome-readme](https://github.com/matiassingers/awesome-readme).

## File Structure

- `prompts/`: Contains the prompt files used to guide the AI models in generating improved README files.
- `[repo]/prompt-[number]/`: Contains the output files from different AI models (e.g., `chatgpt.md`, `deepseek.md`, `copilot.md`) for each prompt number.
- `[repo]/original.md`: Contains the original README file of the repository.
- `repo_meta.py`: Contains a script for extracting metadata from a repository using Octokitpy library.

## Installation

To run the repo_meta.py script, you need to install the Octokitpy library. You can do the following:

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows use .venv\Scripts\activate
pip install octokitpy
python repo_meta.py
```

## Input

The input is a prompt from the `prompts` directory followed by the raw content of an existing README file.

## Output

The output is the "improved" README file generated by the AI model.

## Methodology

The prompts were provided to different AI models with new chat interfaces to prevent any influence from previous interactions. We instructed the model to follow closely best practices, open source standards and GitHub's recommendations on READMEs. The web interface of these models provided a copy button which allowed the output to be copied directly into a markdown file. The outputs were then compared against the original README files to assess improvements.

## Philosophy

Why not provide the entire repository as input to the AI models? While it is possible to do so, it is an expensive approach and doesn't scale effectively. Each interaction, query, or investigation by a model is measured in tokens, directly translating into monetary cost. A potential improvement could be supplying repository metadata gathered from GitHub's API, which would provide the AI more context.

Therefor a well crafted README file can optimize the interaction with the AI model.

## Limitations

- Due to the free tier limitations, long README files may not be fully processed by the AI models causing some sections to be truncated. This is a limitation of the token count in the free tier of the AI models.

- VSCode's Copilot extension gave a roadblock by blocking requests since it considered the README file content as "public code" and would not moved forward with the request. We opted to use the Copilot web interface instead, which allowed us to bypass this limitation.

- 

## Results

Interesting results were observed due to the README files being structured in different manners and formats. Some README files were more structure and detailed causing the AI models to truncate README files, while other README files were short and not structured causing limitations in what the AI models could improve.

A possible improvement could be supplying short README files with repository metadata gathered from GitHub's API, which would provide the AI more context.